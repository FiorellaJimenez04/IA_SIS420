{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#En un entorno se buscará que el agente rodee a una entidad que está posicionada de manera aleatoria en el mismo.\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.entity_pos = np.random.randint(0, size, 2) #genera una posicion random para la entidad en un entorno de size\n",
        "\n",
        "    def get_state(self, agent_pos):\n",
        "        return np.append(agent_pos, self.entity_pos)\n",
        "        #devuelve un array que contiene la posición del agente y la posición de la entidad, que representa el estado actual del entorno.\n",
        "\n",
        "    def get_reward(self, agent_pos): #recompensa basada en la posicion del agente\n",
        "        return int(np.all(np.abs(agent_pos - self.entity_pos) <= 1))\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "        self.q_table = np.zeros((env.size, env.size, env.size, env.size, 4))\n",
        "\n",
        "    def choose_action(self, state, epsilon):\n",
        "        if np.random.uniform(0, 1) < epsilon:\n",
        "            return np.random.randint(4)\n",
        "        else:\n",
        "            return np.argmax(self.q_table[tuple(state)])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, alpha, gamma):   #actualiza la tabla q basado en la experiencia adquirida, bellman\n",
        "        old_value = self.q_table[tuple(state.tolist() + [action])]  #Valor Q actual para estado y accion\n",
        "        next_max = np.max(self.q_table[tuple(next_state)]) #valor maximo de Q de la mejor accion que el agente podria tomar en el prox estado\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max) # valor actualizado de Q\n",
        "        self.q_table[tuple(state.tolist() + [action])] = new_value #actualiza el nuevo valor calculado en la tabla q\n",
        "\n",
        "def train_agent(agent, episodes, alpha=0.7, gamma=0.9, epsilon=0.6):\n",
        "    rewards = np.zeros((agent.env.size, agent.env.size))  # Para almacenar las recompensas\n",
        "    for episode in range(episodes):\n",
        "        agent_pos = np.random.randint(0, agent.env.size, 2) #inicializa el agente en una posicion aleatoria\n",
        "        while not agent.env.get_reward(agent_pos):\n",
        "            state = agent.env.get_state(agent_pos)\n",
        "           # print(state)\n",
        "            action = agent.choose_action(state, epsilon)\n",
        "           # print(action)\n",
        "            if action == 0:   # arriba\n",
        "                next_pos = agent_pos + [-1, 0]\n",
        "            elif action == 1: # abajo\n",
        "                next_pos = agent_pos + [1, 0]\n",
        "            elif action == 2: # izquierda\n",
        "                next_pos = agent_pos + [0, -1]\n",
        "            else:             # derecha\n",
        "                next_pos = agent_pos + [0, 1]\n",
        "            next_pos = np.clip(next_pos, 0, agent.env.size - 1) #limita al agente\n",
        "            reward = agent.env.get_reward(next_pos) #recompensa para la nueva posicion del agente\n",
        "            next_state = agent.env.get_state(next_pos) #nuevo estado despues de la accion\n",
        "            agent.update_q_table(state, action, reward, next_state, alpha, gamma) #actualizacion de la qtable con la experiencia adquirida\n",
        "            agent_pos = next_pos #actualiza la posicion del agente\n",
        "            if reward > 0:  # Si el agente recibe una recompensa, marcamos esa posición en la matriz\n",
        "                rewards[tuple(agent_pos)] = 1\n",
        "    return rewards\n",
        "\n",
        "def plot_rewards(rewards, entity_pos):\n",
        "    # Crear una figura y un eje\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Dibujar el entorno\n",
        "    ax.imshow(rewards, cmap='gray')\n",
        "\n",
        "    # Dibujar la entidad\n",
        "    ax.plot(entity_pos[1], entity_pos[0], 'ro')\n",
        "\n",
        "    # Mostrar la figura\n",
        "    plt.show()\n",
        "\n",
        "# Crear el entorno y el agente\n",
        "env = Environment(size=7)\n",
        "agent = Agent(env)\n",
        "\n",
        "# Num_episodes\n",
        "#rewards = train_agent(agent, episodes=400)\n",
        "rewards = train_agent(agent, episodes=400)\n",
        "\n",
        "# Graficar las recompensas\n",
        "plot_rewards(rewards, env.entity_pos)\n",
        "\n",
        "# Asignar un valor de 100 a la posición de la entidad en la matriz de recompensas\n",
        "rewards[tuple(env.entity_pos)] = 100\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "GGRmNcHNTILx",
        "outputId": "fb5554de-61d4-4a05-fb19-f8e10f71d548"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar las opciones de impresión de NumPy\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# Ahora, cuando imprimas la matriz, se mostrará completa\n",
        "print(rewards)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeldVp_ZZL3-",
        "outputId": "d79e36c3-5fb0-4ba4-a36a-479480500010"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   1.   1.]\n",
            " [  0.   0.   0.   0.   0.   1. 100.]]\n"
          ]
        }
      ]
    }
  ]
}